# OpenBMB
OpenBMBå¼€æºç¤¾åŒºç”±æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤å’Œé¢å£æ™ºèƒ½å…±åŒæ”¯æŒå‘èµ·ã€‚

## MiniCPM-2B

###  TL;DR
MiniCPM æ˜¯é¢å£æ™ºèƒ½ä¸æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤å…±åŒå¼€æºçš„ç³»åˆ—ç«¯ä¾§å¤§æ¨¡å‹ï¼Œä¸»ä½“è¯­è¨€æ¨¡å‹ MiniCPM-2B ä»…æœ‰ 24äº¿ï¼ˆ2.4Bï¼‰çš„éè¯åµŒå…¥å‚æ•°é‡, æ€»è®¡2.7Bå‚æ•°é‡ã€‚
- ç»è¿‡ SFT åï¼ŒMiniCPM-2B åœ¨å…¬å¼€ç»¼åˆæ€§è¯„æµ‹é›†ä¸Šä¸ Mistral-7B è¡¨ç°ç›¸è¿‘ï¼ˆä¸­æ–‡ã€æ•°å­¦ã€ä»£ç èƒ½åŠ›æ›´ä¼˜ï¼‰ï¼Œæ•´ä½“æ€§èƒ½è¶…è¶Š Llama2-13Bã€MPT-30Bã€Falcon-40B ç­‰æ¨¡å‹ã€‚
- ç»è¿‡ DPO åï¼ŒMiniCPM-2B åœ¨å½“å‰æœ€æ¥è¿‘ç”¨æˆ·ä½“æ„Ÿçš„è¯„æµ‹é›† MTBench ä¸Šä¹Ÿè¶…è¶Šäº† Llama2-70B-Chatã€Vicuna-33Bã€Mistral-7B-Instruct-v0.1ã€Zephyr-7B-alpha ç­‰ä¼—å¤šä»£è¡¨æ€§å¼€æºå¤§æ¨¡å‹ã€‚
- ä»¥ MiniCPM-2B ä¸ºåŸºç¡€æ„å»ºç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹ MiniCPM-V 2.0ï¼Œåœ¨å¤šä¸ªæµ‹è¯•åŸºå‡†ä¸­å®ç°äº† 7B ä»¥ä¸‹æ¨¡å‹çš„æœ€ä½³æ€§èƒ½ï¼Œåœ¨ OpenCompass æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 9.6Bã€CogVLM-Chat 17.4B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚MiniCPM-V 2.0 è¿˜å±•ç°å‡ºé¢†å…ˆçš„ OCR èƒ½åŠ›ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Šæ¥è¿‘ Gemini Proã€‚
- ç»è¿‡ Int4 é‡åŒ–åï¼ŒMiniCPM å¯åœ¨æ‰‹æœºä¸Šè¿›è¡Œéƒ¨ç½²æ¨ç†ï¼Œæµå¼è¾“å‡ºé€Ÿåº¦ç•¥é«˜äºäººç±»è¯´è¯é€Ÿåº¦ã€‚MiniCPM-V ä¹Ÿç›´æ¥è·‘é€šäº†å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨æ‰‹æœºä¸Šçš„éƒ¨ç½²ã€‚
- ä¸€å¼ 1080/2080å¯é«˜æ•ˆå‚æ•°å¾®è°ƒï¼Œä¸€å¼ 3090/4090å¯å…¨å‚æ•°å¾®è°ƒï¼Œä¸€å°æœºå™¨å¯æŒç»­è®­ç»ƒ MiniCPMï¼ŒäºŒæ¬¡å¼€å‘æˆæœ¬è¾ƒä½ã€‚

### News
- 2024/04/11 å¼€æº[MiniCPM-V-2.0](https://huggingface.co/openbmb/MiniCPM-V-2.0)ã€[MiniCPM-2B-128k](https://huggingface.co/openbmb/MiniCPM-2B-128k)ã€[MiniCPM-MoE-8x2B](https://huggingface.co/openbmb/MiniCPM-MoE-8x2B)å’Œ[MiniCPM-1B](https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16)ï¼ç‚¹å‡»[è¿™é‡Œ](https://openbmb.vercel.app/?category=Chinese+Blog)æŸ¥çœ‹æŠ€æœ¯åšå®¢ã€‚** 
- 2024/03/16 MiniCPM-2B çš„30ä½™ä¸ªä¸­é—´æ£€æŸ¥ç‚¹å¼€æ”¾äº†ï¼[HuggingFaceé“¾æ¥](https://huggingface.co/openbmb/MiniCPM-2B-history)
- 2024/02/08 æˆ‘ä»¬æ›´æ–°äº†[llama-formatçš„æ¨¡å‹æƒé‡](#llamaformat)ï¼Œæ–¹ä¾¿å¤§å®¶æ›´åŠ å¿«æ·åœ°ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚
- 2024/02/01 åˆå§‹å‘å¸ƒã€‚

### License 
æœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æº

MiniCPM æ¨¡å‹æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª â€œé€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒâ€ã€‚

MiniCPM æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚

å¦‚éœ€å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·è”ç³»cpm@modelbest.cnæ¥è·å–ä¹¦é¢æˆæƒï¼Œåœ¨ç™»è®°åäº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨ã€‚

This repository is released under the Apache-2.0 License.

The usage of MiniCPM model weights must strictly follow the General Model License (GML).

The models and weights of MiniCPM are completely free for academic research.

If you intend to utilize the model for commercial purposes, please reach out to cpm@modelbest.cn to obtain the certificate of authorization.

### Reference
[Homepage](https://www.openbmb.cn/home)

[MiniCPM æŠ€æœ¯æŠ¥å‘Š](https://shengdinghu.notion.site/MiniCPM-c805a17c5c8046398914e47f0542095a)

[Technical Report ](https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20?pvs=4)

[GITHUB](https://github.com/OpenBMB/MiniCPM)

[Hugging Face](https://huggingface.co/openbmb)

## MiniCPM-S-1B

###  TL;DR
The utilization of activation sparsity, namely the existence of considerable weakly-contributed elements among activation outputs, is a promising method for inference acceleration of large language models (LLMs) ([Liu et al., 2023](https://proceedings.mlr.press/v202/liu23am/liu23am.pdf); [Song et al., 2023](https://arxiv.org/pdf/2312.12456.pdf)). Concretely, acceleration methods based on activation sparsity usually achieve higher inference speed by making wiser resource allocation and computation policies to avoid resource waste on these weakly-contributed parameters.

Adopting ReLU as the activation function is a straightforward method to achieve activation sparsity. However, most recent mainstream LLMs adopt activation functions without intrinsic sparsity (e.g., GELU and Swish). Some efforts ([Zhang et al., 2022](https://aclanthology.org/2022.findings-acl.71.pdf); [Mirzadeh et al., 2023](https://arxiv.org/pdf/2310.04564.pdf); [Zhang et al., 2024](https://arxiv.org/pdf/2402.03804.pdf)) introduce ReLU or its variants as the substitutive activation function to help non-ReLU LLMs achieve activation sparsity and inference acceleration, but few can concurrently obtain high sparsity and comparable task-specific performance.

In this work, we introduce a simple and effective sparsification method named "ProSparse" to push LLMs for higher activation sparsity while maintaining comparable performance. By applying ProSparse to Swish-activated LLaMA2-7B, LLaMA2-13B, and MiniCPM-1B, we obtain ReLU-activated models with high sparsity of 89.32%, 88.80%, and 87.89%, respectively, while their performance is comparable to the original version. These present the most sparsely activated models among open-source LLaMA versions and competitive end-size models, considerably surpassing ReluLLaMA-7B (66.98%) and ReluLLaMA-13B (71.56%). Further inference acceleration experiments demonstrate the practical speedup effects of higher sparsity on both [PowerInfer](https://arxiv.org/pdf/2312.12456.pdf) and our two sparse GPU [operators](https://github.com/Raincleared-Song/sparse_gpu_operator).

### News
- 2024/07/04 å‘å¸ƒ MiniCPM-S-1Bã€‚

### License 
This repository is released under the [Apache-2.0](https://github.com/OpenBMB/MiniCPM/blob/main/LICENSE) License.

The usage of MiniCPM model weights must strictly follow [the General Model License (GML)](https://github.com/OpenBMB/General-Model-License/blob/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md).

The models and weights of MiniCPM are completely free for academic research.

If you intend to utilize the model for commercial purposes, please reach out to cpm@modelbest.cn to obtain the certificate of authorization.

### Reference
[Hugging Face](https://huggingface.co/openbmb/MiniCPM-S-1B-sft/)

Paper: [link](https://arxiv.org/pdf/2402.13516.pdf) (Note: `MiniCPM-S-1B` is denoted as `ProSparse-1B` in the paper.)

## MiniCPM-V

###  TL;DR
**MiniCPM-V**æ˜¯é¢å‘å›¾æ–‡ç†è§£çš„ç«¯ä¾§å¤šæ¨¡æ€å¤§æ¨¡å‹ç³»åˆ—ã€‚è¯¥ç³»åˆ—æ¨¡å‹æ¥å—å›¾åƒå’Œæ–‡æœ¬è¾“å…¥ï¼Œå¹¶æä¾›é«˜è´¨é‡çš„æ–‡æœ¬è¾“å‡ºã€‚è‡ª2024å¹´2æœˆä»¥æ¥ï¼Œæˆ‘ä»¬å…±å‘å¸ƒäº†4ä¸ªç‰ˆæœ¬æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°**é¢†å…ˆçš„æ€§èƒ½å’Œé«˜æ•ˆçš„éƒ¨ç½²**ï¼Œç›®å‰è¯¥ç³»åˆ—æœ€å€¼å¾—å…³æ³¨çš„æ¨¡å‹åŒ…æ‹¬ï¼š

- **MiniCPM-Llama3-V 2.5**ï¼šğŸ”¥ğŸ”¥ğŸ”¥ MiniCPM-Vç³»åˆ—çš„æœ€æ–°ã€æ€§èƒ½æœ€ä½³æ¨¡å‹ã€‚æ€»å‚æ•°é‡8Bï¼Œå¤šæ¨¡æ€ç»¼åˆæ€§èƒ½è¶…è¶Š GPT-4V-1106ã€Gemini Proã€Claude 3ã€Qwen-VL-Max ç­‰å•†ç”¨é—­æºæ¨¡å‹ï¼ŒOCR èƒ½åŠ›åŠæŒ‡ä»¤è·Ÿéšèƒ½åŠ›è¿›ä¸€æ­¥æå‡ï¼Œå¹¶æ”¯æŒè¶…è¿‡30ç§è¯­è¨€çš„å¤šæ¨¡æ€äº¤äº’ã€‚é€šè¿‡ç³»ç»Ÿä½¿ç”¨æ¨¡å‹é‡åŒ–ã€CPUã€NPUã€ç¼–è¯‘ä¼˜åŒ–ç­‰é«˜æ•ˆæ¨ç†æŠ€æœ¯ï¼ŒMiniCPM-Llama3-V 2.5 å¯ä»¥å®ç°é«˜æ•ˆçš„ç»ˆç«¯è®¾å¤‡éƒ¨ç½²ã€‚

- **MiniCPM-V 2.0**ï¼šMiniCPM-Vç³»åˆ—çš„æœ€è½»é‡çº§æ¨¡å‹ã€‚æ€»å‚æ•°é‡2Bï¼Œå¤šæ¨¡æ€ç»¼åˆæ€§èƒ½è¶…è¶Š Yi-VL 34Bã€CogVLM-Chat 17Bã€Qwen-VL-Chat 10B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼Œå¯æ¥å— 180 ä¸‡åƒç´ çš„ä»»æ„é•¿å®½æ¯”å›¾åƒè¾“å…¥ï¼Œå®ç°äº†å’Œ Gemini Pro ç›¸è¿‘çš„åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä»¥åŠå’Œ GPT-4V ç›¸åŒ¹çš„ä½å¹»è§‰ç‡ã€‚

MiniCPM-V 2.6 is the latest and most capable model in the MiniCPM-V series. The model is built on SigLip-400M and Qwen2-7B with a total of 8B parameters. It exhibits a significant performance improvement over MiniCPM-Llama3-V 2.5, and introduces new features for multi-image and video understanding. Notable features of MiniCPM-V 2.6 include:


### News
* [2024.08.06] ğŸ”¥ğŸ”¥ğŸ”¥ We open-source MiniCPM-V 2.6, which outperforms GPT-4V on single image, multi-image and video understanding. It advances popular features of MiniCPM-Llama3-V 2.5, and can support real-time video understanding on iPad. Try it now!
* [2024.08.03] MiniCPM-Llama3-V 2.5 technical report is released! See here.
* [2024.07.19] MiniCPM-Llama3-V 2.5 supports vLLM now! See here.
* [2024.05.28] ğŸš€ğŸš€ğŸš€ MiniCPM-Llama3-V 2.5 now fully supports its feature in llama.cpp and ollama! Please pull the latest code of our provided forks (llama.cpp, ollama). GGUF models in various sizes are available here. MiniCPM-Llama3-V 2.5 series is not supported by the official repositories yet, and we are working hard to merge PRs. Please stay tuned!
* [2024.05.28] ğŸ’« We now support LoRA fine-tuning for MiniCPM-Llama3-V 2.5, using only 2 V100 GPUs! See more statistics here.
* [2024.05.23] æˆ‘ä»¬æ·»åŠ äº†Phi-3-vision-128k-instructä¸MiniCPM-Llama3-V 2.5çš„å…¨é¢å¯¹æ¯”ï¼ŒåŒ…æ‹¬åŸºå‡†æµ‹è¯•è¯„ä¼°å’Œå¤šè¯­è¨€èƒ½åŠ› ğŸŒŸğŸ“ŠğŸŒã€‚ç‚¹å‡»[è¿™é‡Œ](./docs/compare_with_phi-3_vision.md)æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯ã€‚
<!-- * [2024.05.22] æˆ‘ä»¬è¿›ä¸€æ­¥æå‡äº†ç«¯ä¾§æ¨ç†é€Ÿåº¦ï¼å®ç°äº† 6-8 tokens/s çš„æµç•…ä½“éªŒï¼Œæ¬¢è¿è¯•ç”¨ï¼ -->
* [2024.05.20] æˆ‘ä»¬å¼€æºäº† MiniCPM-Llama3-V 2.5ï¼Œå¢å¼ºäº† OCR èƒ½åŠ›ï¼Œæ”¯æŒ 30 å¤šç§è¯­è¨€ï¼Œå¹¶é¦–æ¬¡åœ¨ç«¯ä¾§å®ç°äº† GPT-4V çº§çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼æˆ‘ä»¬æä¾›äº†[é«˜æ•ˆæ¨ç†](#æ‰‹æœºç«¯éƒ¨ç½²)å’Œ[ç®€æ˜“å¾®è°ƒ](./finetune/readme.md)çš„æ”¯æŒï¼Œæ¬¢è¿è¯•ç”¨ï¼
* [2024.04.23] æˆ‘ä»¬å¢åŠ äº†å¯¹ [vLLM](#vllm) çš„æ”¯æŒï¼Œæ¬¢è¿ä½“éªŒï¼
* [2024.04.18] æˆ‘ä»¬åœ¨ HuggingFace Space æ–°å¢äº† MiniCPM-V 2.0 çš„ [demo](https://huggingface.co/spaces/openbmb/MiniCPM-V-2)ï¼Œæ¬¢è¿ä½“éªŒï¼
* [2024.04.17] MiniCPM-V 2.0 ç°åœ¨æ”¯æŒç”¨æˆ·éƒ¨ç½²æœ¬åœ° [WebUI Demo](#æœ¬åœ°webui-demoéƒ¨ç½²) äº†ï¼Œæ¬¢è¿è¯•ç”¨!
* [2024.04.15] MiniCPM-V 2.0 ç°åœ¨å¯ä»¥é€šè¿‡ SWIFT æ¡†æ¶ [å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-v-2æœ€ä½³å®è·µ.md) äº†ï¼Œæ”¯æŒæµå¼è¾“å‡º!
* [2024.04.12] æˆ‘ä»¬å¼€æºäº† MiniCPM-V 2.0ï¼Œè¯¥æ¨¡å‹åˆ·æ–°äº† OCRBench å¼€æºæ¨¡å‹æœ€ä½³æˆç»©ï¼Œåœ¨åœºæ™¯æ–‡å­—è¯†åˆ«èƒ½åŠ›ä¸Šæ¯”è‚© Gemini Proï¼ŒåŒæ—¶è¿˜åœ¨ç»¼åˆäº† 11 ä¸ªä¸»æµå¤šæ¨¡æ€å¤§æ¨¡å‹è¯„æµ‹åŸºå‡†çš„ <a href="https://rank.opencompass.org.cn/leaderboard-multimodal">OpenCompass</a> æ¦œå•ä¸Šè¶…è¿‡äº† Qwen-VL-Chat 10Bã€CogVLM-Chat 17B å’Œ Yi-VL 34B ç­‰æ›´å¤§å‚æ•°è§„æ¨¡çš„æ¨¡å‹ï¼ç‚¹å‡»<a href="https://openbmb.vercel.app/minicpm-v-2">è¿™é‡Œ</a>æŸ¥çœ‹ MiniCPM-V 2.0 æŠ€æœ¯åšå®¢ã€‚
* [2024.03.14] MiniCPM-V ç°åœ¨æ”¯æŒ SWIFT æ¡†æ¶ä¸‹çš„[å¾®è°ƒ](https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/minicpm-væœ€ä½³å®è·µ.md)äº†ï¼Œæ„Ÿè°¢ [Jintao](https://github.com/Jintao-Huang) çš„è´¡çŒ®ï¼
* [2024.03.01] MiniCPM-V ç°åœ¨æ”¯æŒåœ¨ Mac ç”µè„‘ä¸Šè¿›è¡Œéƒ¨ç½²ï¼
* [2024.02.01] æˆ‘ä»¬å¼€æºäº† MiniCPM-V å’Œ OmniLMM-12Bï¼Œåˆ†åˆ«å¯ä»¥æ”¯æŒé«˜æ•ˆçš„ç«¯ä¾§éƒ¨ç½²å’ŒåŒè§„æ¨¡é¢†å…ˆçš„å¤šæ¨¡æ€èƒ½åŠ›ï¼

### 
MiniCPM-V ä¾èµ– timm

### License 

æœ¬ä»“åº“ä¸­ä»£ç ä¾ç…§ Apache-2.0 åè®®å¼€æº

æœ¬é¡¹ç›®ä¸­æ¨¡å‹æƒé‡çš„ä½¿ç”¨éµå¾ª â€œ[é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ](https://github.com/OpenBMB/General-Model-License/blob/main/é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ.md)â€ã€‚

æœ¬é¡¹ç›®ä¸­æ¨¡å‹æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ã€‚

å¦‚éœ€å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œè¯·è”ç³» cpm@modelbest.cn æ¥è·å–ä¹¦é¢æˆæƒï¼Œç™»è®°åå¯ä»¥å…è´¹å•†ä¸šä½¿ç”¨ã€‚

The code in this repo is released according to [Apache-2.0](https://github.com/OpenBMB/MiniCPM/blob/main/LICENSE)

The usage of MiniCPM-V's and OmniLMM's parameters is subject to "[General Model License Agreement - Source Notes - Publicity Restrictions - Commercial License](https://github.com/OpenBMB/General-Model-License/blob/main/é€šç”¨æ¨¡å‹è®¸å¯åè®®-æ¥æºè¯´æ˜-å®£ä¼ é™åˆ¶-å•†ä¸šæˆæƒ.md)"

The parameters are fully open to academic research

Please contact cpm@modelbest.cn to obtain written authorization for commercial uses. Free commercial use is also allowed after registration.

### Reference
[Homepage](https://www.openbmb.cn/home)

[MiniCPM-V æŠ€æœ¯æŠ¥å‘Š](https://openbmb.vercel.app/minicpm-v-2)

[GITHUB](https://github.com/OpenBMB/MiniCPM-V/)

[Hugging Face](https://huggingface.co/openbmb)
