# THUDM
The Knowledge Engineering Group (KEG) & Data Mining (THUDM) at Tsinghua University.

æ™ºè°±AIæ˜¯ç”±æ¸…åå¤§å­¦è®¡ç®—æœºç³»æŠ€æœ¯æˆæœè½¬åŒ–è€Œæ¥çš„å…¬å¸

## GLM-4

### TL;DR
GLM-4-9B æ˜¯æ™ºè°± AI æ¨å‡ºçš„æœ€æ–°ä¸€ä»£é¢„è®­ç»ƒæ¨¡å‹ GLM-4 ç³»åˆ—ä¸­çš„å¼€æºç‰ˆæœ¬ã€‚ åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç å’ŒçŸ¥è¯†ç­‰å¤šæ–¹é¢çš„æ•°æ®é›†æµ‹è¯„ä¸­ï¼Œ
**GLM-4-9B** åŠå…¶äººç±»åå¥½å¯¹é½çš„ç‰ˆæœ¬ **GLM-4-9B-Chat** å‡è¡¨ç°å‡ºè¶…è¶Š Llama-3-8B çš„å“è¶Šæ€§èƒ½ã€‚é™¤äº†èƒ½è¿›è¡Œå¤šè½®å¯¹è¯ï¼ŒGLM-4-9B-Chat
è¿˜å…·å¤‡ç½‘é¡µæµè§ˆã€ä»£ç æ‰§è¡Œã€è‡ªå®šä¹‰å·¥å…·è°ƒç”¨ï¼ˆFunction Callï¼‰å’Œé•¿æ–‡æœ¬æ¨ç†ï¼ˆæ”¯æŒæœ€å¤§ 128K ä¸Šä¸‹æ–‡ï¼‰ç­‰é«˜çº§åŠŸèƒ½ã€‚æœ¬ä»£æ¨¡å‹å¢åŠ äº†å¤šè¯­è¨€æ”¯æŒï¼Œæ”¯æŒåŒ…æ‹¬æ—¥è¯­ï¼ŒéŸ©è¯­ï¼Œå¾·è¯­åœ¨å†…çš„
26 ç§è¯­è¨€ã€‚æˆ‘ä»¬è¿˜æ¨å‡ºäº†æ”¯æŒ 1M ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆçº¦ 200 ä¸‡ä¸­æ–‡å­—ç¬¦ï¼‰çš„ **GLM-4-9B-Chat-1M** æ¨¡å‹å’ŒåŸºäº GLM-4-9B çš„å¤šæ¨¡æ€æ¨¡å‹
GLM-4V-9Bã€‚**GLM-4V-9B** å…·å¤‡ 1120 * 1120 é«˜åˆ†è¾¨ç‡ä¸‹çš„ä¸­è‹±åŒè¯­å¤šè½®å¯¹è¯èƒ½åŠ›ï¼Œåœ¨ä¸­è‹±æ–‡ç»¼åˆèƒ½åŠ›ã€æ„ŸçŸ¥æ¨ç†ã€æ–‡å­—è¯†åˆ«ã€å›¾è¡¨ç†è§£ç­‰å¤šæ–¹é¢å¤šæ¨¡æ€è¯„æµ‹ä¸­ï¼ŒGLM-4V-9B
è¡¨ç°å‡ºè¶…è¶Š GPT-4-turbo-2024-04-09ã€Gemini
1.0 Proã€Qwen-VL-Max å’Œ Claude 3 Opus çš„å“è¶Šæ€§èƒ½ã€‚

### News

- 2024/6/5 released GLM-4-9Bã€GLM-4-9B-Chatã€GLM-4-9B-Chat-1Mã€GLM-4V-9B

### License 

+ GLM-4 æ¨¡å‹çš„æƒé‡çš„ä½¿ç”¨åˆ™éœ€è¦éµå¾ª [æ¨¡å‹åè®®](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE)ã€‚

+ æœ¬å¼€æºä»“åº“çš„ä»£ç åˆ™éµå¾ª [Apache 2.0](LICENSE) åè®®ã€‚

è¯·æ‚¨ä¸¥æ ¼éµå¾ªå¼€æºåè®®ã€‚

+ The use of GLM-4 model weights must follow
  the [Model License](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE).

+ The code in this open source repository follows the [Apache 2.0](LICENSE) license.

Please strictly follow the open source license.


### Reference
[GITHUB](https://github.com/THUDM/GLM-4)

[Hugging Face](https://huggingface.co/THUDM/)


## CogVLM2

###  TL;DR
We launch a new generation of **CogVLM2** series of models and open source two models based
on [Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct). Compared with the previous
generation of CogVLM open source models, the CogVLM2 series of open source models have the following improvements:

1. Significant improvements in many benchmarks such as `TextVQA`, `DocVQA`.
2. Support **8K** content length.
3. Support image resolution up to **1344 * 1344**.
4. Provide an open source model version that supports both **Chinese and English**.

### News
- ğŸ”¥ğŸ”¥ **News**: ``2024/5/24```: We have released the Int4 version model, which requires only 16GB of video memory for inference. Welcome to experience it!
- ğŸ”¥ **News**: ``2024/5/20``: We released the next generation model CogVLM2, which is based on llama3-8b and is equivalent (or better) to GPT-4V in most cases ! Welcome to download!

### 
CogVLM2 ä¾èµ– xformers

### License 
This model is released under the CogVLM2 [CogVLM2 LICENSE](MODEL_LICENSE). For models built with Meta Llama 3, please
also adhere to the [LLAMA3_LICENSE](https://llama.meta.com/llama3/license/).

è¯¥æ¨¡å‹æ ¹æ® [CogVLM2 LICENSE](MODEL_LICENSE) è®¸å¯è¯å‘å¸ƒã€‚å¯¹äºä½¿ç”¨äº†Meta Llama
3åŸºåº§æ¨¡å‹æ„å»ºçš„æ¨¡å‹ï¼Œéœ€è¦åŒæ—¶éµå®ˆ [LLAMA3_LICENSE](https://llama.meta.com/llama3/license/) è®¸å¯è¯ã€‚

### Reference
[GITHUB](https://github.com/THUDM/CogVLM2/)

[Hugging Face](https://huggingface.co/THUDM/)

