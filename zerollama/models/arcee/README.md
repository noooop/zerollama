# Arcee Spark
Arcee Spark is a powerful 7B parameter language model that punches well above its weight class. Initialized from Qwen2, this model underwent a sophisticated training process:

1. Fine-tuned on 1.8 million samples
2. Merged with Qwen2-7B-Instruct using Arcee's mergekit
3. Further refined using Direct Preference Optimization (DPO)

This meticulous process results in exceptional performance, with Arcee Spark achieving the highest score on MT-Bench for models of its size, outperforming even GPT-3.5 on many tasks.

# Key Features

- 7B parameters
- State-of-the-art performance for its size
- Initialized from Qwen2
- Advanced training process including fine-tuning, merging, and DPO
- Highest MT-Bench score in the 7B class
- Outperforms GPT-3.5 on many tasks
- Has a context length of 128k tokens, making it ideal for tasks requiring many conversation turns or working with large amounts of text.


# News
* 2024-06-22: 发布 Arcee-Spark


### License
Arcee Spark is released under the Apache 2.0 license.


### Reference
[Hugging Face](https://huggingface.co/arcee-ai/)

