{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b62ad0c-06cf-4275-a3f7-01a41d2b548b",
   "metadata": {},
   "source": [
    "# 0. zerollama.agents 支持多种客户端"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ace4a-cc98-4225-b113-9983488ddb73",
   "metadata": {},
   "source": [
    "首先将zerollama目录加入python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138f0ee2-cb37-4dd0-96d4-4dc43cc91f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "pwd = Path(os.getcwd())\n",
    "sys.path.append(str(pwd.parent.parent.parent))\n",
    "os.chdir(str(pwd.parent.parent.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689f9cc-6f44-4ca7-829d-18282ff6984e",
   "metadata": {},
   "source": [
    "导入ConversableAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5134a9ed-da5e-4dde-8959-98fda3bcc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zerollama.agents import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f1c02-33f2-46a2-b366-4e1b98af48a1",
   "metadata": {},
   "source": [
    "演示使用Qwen/Qwen2-7B-Instruct-GPTQ-Int4模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cff234-062d-4f56-be5f-cf82453ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Qwen/Qwen2-7B-Instruct-GPTQ-Int4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5990d-7e02-422e-9788-5c3eead6ccd4",
   "metadata": {},
   "source": [
    "演示的提示词为 \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d455a166-e33e-4f8e-89c8-c29a41789fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65113e5c-4a8d-4118-9173-6d3027aadb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'type': 'zerollama', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型是一种深度学习模型，通常使用大量文本数据进行训练，旨在生成或预测与给定输入相关的自然语言文本。它们运用了神经网络架构的技术，尤其是Transformer模型，能够理解和生成复杂的语言结构。\n",
      "\n",
      "### 特点：\n",
      "\n",
      "1. **大规模训练**：大型语言模型通常基于庞大的数据集训练，包含从网页、文档、书籍、社交媒体等多种来源获取的信息，以学习到广泛的语言模式。\n",
      "\n",
      "2. **双向上下文理解**：通过Transformer架构中的多头注意力机制，模型可以理解输入文本中的远距离依赖关系，实现对前后文的理解和预测。\n",
      "\n",
      "3. **语言生成**：不仅可以预测最可能的下一个词汇序列，还能生成全新的、连贯的、创造性的文本，包括故事、新闻、评论、对话等。\n",
      "\n",
      "4. **多语言能力**：一些大型语言模型能够处理多种语言，并通过机器翻译功能在不同语言间转换文本。\n",
      "\n",
      "### 应用领域：\n",
      "\n",
      "- **自然语言处理**：用于文本理解和生成，包括搜索引擎优化、聊天机器人、智能助手等。\n",
      "\n",
      "- **个性化推荐**：在推荐系统中优化用户内容推荐，并增强用户体验。\n",
      "\n",
      "- **机器翻译**：实现跨语言文本转换，便于国际间\n",
      "stream=True\n",
      "大型语言模型是基于深度学习技术构建的复杂人工智能模型，专门设计用于生成或理解人类可读文本。这些模型通过训练大规模、多样化的文本数据集来学习语言的表达规律和语义，可以生成包括但不限于以下能力的文本内容：\n",
      "\n",
      "1. **文本生成**：能够根据给定的前提创作出高质量的文本内容，覆盖从短语、段落到整篇文章的生成，包括故事、诗歌、剧本、新闻报道、邮件、代码等。\n",
      "\n",
      "2. **对话交互**：这些模型通常经过预训练，可以在对话中提供持续的回答，构建类似人类的交互体验。\n",
      "\n",
      "3. **多语言支持**：大型语言模型能够处理多种语言，部分模型甚至能支持200多种语言，并具备翻译能力。\n",
      "\n",
      "4. **跨领域应用**：大型语言模型在多个领域有广泛的应用，比如内容创作、智能客服、法律文本分析、教育助手、辅助写作等。\n",
      "\n",
      "5. **自监督学习**：模型通常采用自监督学习方式（即通过大量无标记文本进行训练），而现代模型在预训练阶段还可能大量使用有标签的数据集进一步优化其性能。\n",
      "\n",
      "### 几个典型例子：\n",
      "\n",
      "- **通义千问（\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'openai', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'base_url': 'http://localhost:8080/v1/', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型是一种基于深度学习技术的自然语言处理工具，其核心是在大量文本数据上进行训练，从而能够理解、生成和翻译自然语言文本。这类模型能够学习到语言的复杂结构、语义和上下文关系，使其不仅能够完成简单的文本生成，还能在复杂任务中展现出多样性和创造性。\n",
      "\n",
      "大型语言模型可以分为以下几种类型：\n",
      "\n",
      "1. **Transformer模型**：这是近年来兴起并广泛应用的一种基于自注意力机制的深度神经网络模型。由谷歌于2017年提出，结构上将原本的循环神经网络改为了多头自注意力机制和前馈神经网络，极大地提高了语言处理的效率和效果。\n",
      "\n",
      "2. **大型预训练模型**（如GPT系列）：基于Transformer这类架构，使用大量文本数据在无标签的情况下进行预训练，学习到通用的语言表示。之后可以根据具体任务进行微调，应用于文本生成、问答、代码编写、翻译等多种场景。\n",
      "\n",
      "3. **LLM（Large Language Model）**：这个术语通常用来指大型语言模型，强调大型基模型能够处理各种周期性和多变的语言任务。类似于我，能够回答问题、创作文字、总结文本、生成代码、识别情绪、分析\n",
      "stream=True\n",
      "大型语言模型（Large Language Model，LLM）是近年来自然语言处理领域的一项重大突破。它们是基于深度学习架构训练的复杂神经网络模型，能够理解和生成复杂的自然语言文本。相比于传统的基于规则的语言模型，大型语言模型的特点在于其通过大规模数据集进行无监督学习，可以展现出相当程度的上下文理解和语言生成能力。\n",
      "\n",
      "在技术层面，大型语言模型通常采用Transformer架构，该架构能够有效处理序列数据，同时利用自注意力机制捕捉输入文本中的长距离依赖关系。相较于早期的循环神经网络（RNN）， Transformer架构能在保持简洁性的同时大幅提升模型的学习效率和性能。\n",
      "\n",
      "大型语言模型的应用极为广泛，包括但不限于：\n",
      "1. **文本生成**：撰写新闻、故事、对话、代码等。\n",
      "2. **语言翻译**：将文本从一种语言自动翻译成另一种语言。\n",
      "3. **聊天机器人**：创建能够理解并回答人类问题的对话系统。\n",
      "4. **文本摘要**：自动从长文本中提取关键信息，形成简短的摘要。\n",
      "5. **情感分析**：评估文本中表达的情感，如积极、消极或中立。\n",
      "6. **代码生成**：根据给定的上下文生成代码片段\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'ollama', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型其实指的是当前AI领域中，尤其是自然语言处理领域里使用的具有大规模参数、能在多种语言任务上表现出强大能力的机器学习模型。这类模型通过大量的文本数据进行训练，学习到语言的复杂结构和模式，进而能够生成与给定指令相关的、连贯的、有意义的文本内容。大型语言模型的几个关键特性包括：\n",
      "\n",
      "1. **参数规模庞大**：现代大型语言模型往往包含数以亿计的参数，相比之下早期的模型参数规模较小。大规模参数使模型能够学习到语言更高的抽象层次和复杂的语境。\n",
      "\n",
      "2. **多任务适应性**：大型语言模型显示出了在多种语言处理任务上（如文本生成、翻译、问答、代码编写、写作）的强大适应性。这一能力得益于模型从大量多领域的数据中学习广泛的语言模式。\n",
      "\n",
      "3. **基于Transformer架构**：几乎所有主流的大型语言模型（如GPT系列、BERT、T5、CodeX-fold等）都是基于Transformer架构。该架构使得模型能够有效处理序列到序列（seq2seq）任务，显著提高了多语境下生成文本的连贯性和准确性。\n",
      "\n",
      "4. **指导式学习和自监督学习**：通常\n",
      "stream=True\n",
      "大型语言模型，也被称为预训练模型或底层模型，是在处理各种自然语言任务上效果卓越的复杂神经网络模型。它们通过从大量文本数据中学习模式和规律，具备了生成描述、回答问题、代码编写、甚至是创造故事和诗歌的能力。大型语言模型通常包括以下特点：\n",
      "\n",
      "1. **大规模训练数据集**：这些模型往往使用了数量级达到TB级别的语料库进行训练，覆盖广泛的主题和领域，从而使它们具备了普遍的知识背景。\n",
      "\n",
      "2. **深度学习架构**：通常基于递归神经网络（RNN）、变换器（Transformer）或其他复杂架构，这些结构允许模型处理序列数据并理解和生成复杂语言结构。\n",
      "\n",
      "3. **高平行计算资源**：训练大型语言模型需要大量的计算资源和时间。它们经常使用分布式训练技术，部署在大规模计算集群中。\n",
      "\n",
      "4. **广泛应用**：大型语言模型在诸多领域中有应用，包括但不限于自动文摘、代码生成、对话系统、智能客服、翻译、文本完成和决策辅助系统。\n",
      "\n",
      "5. **基础模型与微调**：大型语言模型经常作为“基础模型”发布，用于各种特定任务的“微调”工作。微调是指在原始\n"
     ]
    }
   ],
   "source": [
    "for llm_config in [\n",
    "    {\"type\": \"zerollama\", \"model\": model, \"global_priority\": False},\n",
    "    {\"type\": \"openai\", \"model\": model, \"base_url\": 'http://localhost:8080/v1/', \"global_priority\": False},\n",
    "    {\"type\": \"ollama\", \"model\": model, \"global_priority\": False},\n",
    "\n",
    "]:\n",
    "    print(\"-\" * 80)\n",
    "    print(llm_config)\n",
    "    agent = ConversableAgent(\n",
    "        name=\"chatbot\",\n",
    "        llm_config=llm_config,\n",
    "    )\n",
    "\n",
    "    print(\"stream=False\")\n",
    "    reply = agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=False,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    )\n",
    "\n",
    "    print(reply)\n",
    "\n",
    "    print(\"stream=True\")\n",
    "    for part in agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=True,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    ):\n",
    "        print(part, end=\"\", flush=True)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c423d37-628a-4784-bcb3-64cdf23e356a",
   "metadata": {},
   "source": [
    "运行你会看到stream=False一次性输出，stream=False流式输出。vllm默认设定输出512个token，所以会有截断。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0c819-278c-4545-84e1-657bc9ae36c1",
   "metadata": {},
   "source": [
    "## 总结\n",
    "zerollama.agents 支持 ollama和openai客户端、支持zerollama内部通讯协议。非常灵活。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c3d2a-94c9-4d8d-82b8-a537f463af29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
