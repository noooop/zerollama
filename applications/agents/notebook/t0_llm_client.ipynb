{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b62ad0c-06cf-4275-a3f7-01a41d2b548b",
   "metadata": {},
   "source": [
    "# 0. zerollama.agents 支持多种客户端"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09ace4a-cc98-4225-b113-9983488ddb73",
   "metadata": {},
   "source": [
    "首先将zerollama目录加入python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138f0ee2-cb37-4dd0-96d4-4dc43cc91f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "pwd = Path(os.getcwd())\n",
    "sys.path.append(str(pwd.parent.parent.parent))\n",
    "os.chdir(str(pwd.parent.parent.parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d689f9cc-6f44-4ca7-829d-18282ff6984e",
   "metadata": {},
   "source": [
    "导入LLMAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5134a9ed-da5e-4dde-8959-98fda3bcc0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zerollama.agents import LLMAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f1c02-33f2-46a2-b366-4e1b98af48a1",
   "metadata": {},
   "source": [
    "演示使用Qwen/Qwen2-7B-Instruct-GPTQ-Int4模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cff234-062d-4f56-be5f-cf82453ea28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Qwen/Qwen2-7B-Instruct-GPTQ-Int4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d5990d-7e02-422e-9788-5c3eead6ccd4",
   "metadata": {},
   "source": [
    "演示的提示词为 \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d455a166-e33e-4f8e-89c8-c29a41789fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"给我介绍一下大型语言模型。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65113e5c-4a8d-4118-9173-6d3027aadb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "{'type': 'zerollama', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型（Large Language Models, LLMs）是指具有大量参数（通常在数百万到数百亿之间）的深度神经网络模型。这些模型能够生成与所提供的输入文本风格相似的文本，以帮助人类完成一种或多种自然语言处理任务。它们是基于Transformer架构的先进模型，通过学习大规模文本数据集（如维基百科、书籍、新闻文章等）中的语言模式和结构，能够理解和生成高度复杂的语言表达。\n",
      "\n",
      "LLMs在短时间内的崛起主要得益于几个关键技术和策略的综合提高：\n",
      "1. **大规模数据和计算资源**：为了训练大型模型，通常需要大量高质量的标注数据和强大的计算资源，这使得模型能够学习到更丰富的语言模式。\n",
      "2. **深度学习架构的改进**：BERT、GPT、Transformer等架构的提出极大地提高了语言模型的生成质量和效率，它们能够处理更复杂和多样的语言任务。\n",
      "3. **自回归性质**：许多LLMs具有自回归性质，即生成下一个字符取决于前面的字符，这种特性使得模型能够生成连续流畅的文本。\n",
      "4. **预训练和微调**：LLMs通常在大规模无标注数据上进行预训练，后来可以根据特定任务\n",
      "stream=True\n",
      "大型语言模型（Large Language Model）是一种基于深度学习的大型人工智能系统，专门用于生成或理解人类语言。这些模型的基本工作原理是通过对大量文本数据进行训练，学习到不同语言元素之间的复杂关系和模式。大型语言模型在训练时解码语言输入，并根据学习到的模式生成相应的输出。它们的工作基于概率和统计学方法，通过上下文计算可能性较高的词或语句序列。\n",
      "\n",
      "以下是一些大的语言模型的关键特点和应用方向：\n",
      "\n",
      "### 关键特点：\n",
      "\n",
      "1. **超大参数量**：大型语言模型往往包含数以十亿计或更多参数，以捕捉和表示复杂的语言模式。\n",
      "2. **多语言支持**：现代大型语言模型可以适应多种不同的语言，并在跨语言任务上进行翻译和生成。\n",
      "3. **持续学习**：通过与更多文本数据的交互，可以不断学习和改进性能。\n",
      "4. **知识理解**：一些模型不仅能生成文本，还能理解上下文和相关知识背景，包括事实性和非事实性的信息。\n",
      "5. **交互性**：支持响应式的对话和问答，能够根据上文提供连续的、相关的回答或对话。\n",
      "\n",
      "### 应用方向：\n",
      "\n",
      "- **语言翻译\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'openai', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'base_url': 'http://localhost:8080/v1/', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型（Large Language Models）是指当前最先进的自然语言处理（NLP）模型，它们通常具有巨大的参数量和处理过大量文本数据，以学习语言结构、语法、上下文理解、生成文本等复杂的语言任务。这些模型基于深度学习技术，尤其是在Transformer架构上进行了优化，使得它们能够处理和生成文本数据，并在多种语言任务上表现出色，如机器翻译、文本摘要、对话生成、代码编写、故事创作、问答系统等。\n",
      "\n",
      "大型语言模型的特性包括：\n",
      "\n",
      "1. **大规模参数量**：这些模型通常具有数百万至上百亿的参数，有的甚至超过千亿。参数量的增加有助于模型学习更复杂的语言结构和模式。\n",
      "\n",
      "2. **预训练**：大多数大型语言模型采用预训练技术，即在大量未标注的文本数据上进行无监督训练，以学习通用的语言表示。这些模型通常在大规模语料库上进行训练，如英文的Common Crawl、Wikipedia、Stack Exchange等，中文模型也可能使用大量中文文本数据。\n",
      "\n",
      "3. **多语言支持**：大型语言模型不仅支持英语，还支持多种其他语言，包括中文、西班牙语、法语、日语等，这使得它们可以\n",
      "stream=True\n",
      "大型语言模型，通常被称为预训练语言模型（Pre-trained Language Models），是机器学习中的一种重要工具，主要用于生成或理解自然语言文本。这类模型通过在大量文本数据上进行预训练，学习到语言的普遍规律和上下文关联，从而能够对新的、未见过的文本进行理解和生成。\n",
      "\n",
      "### 一些主要的大型语言模型\n",
      "\n",
      "1. **BERT （Bidirectional Encoder Representations from Transformers）**\n",
      "    - **特点**：BERT 是一个双向的深度学习模型，能够理解语言的上下文关系，对于很多自然语言处理任务（如问答、命名实体识别、情感分析等）表现出卓越的性能。\n",
      "    - **应用**：广泛应用于各种自然语言处理任务，包括但不限于阅读理解、文本分类、语义相似度计算等。\n",
      "\n",
      "2. **GPT（Generative Pre-trained Transformer）系列**\n",
      "    - **特点**：GPT 系列模型，如 GPT-2 和 GPT-3，是基于 Transformers 架构的自回归语言模型。它们生成的文本与人类相似度高，能够生成流畅、连贯且上下文相关的文本。\n",
      "    - **应用**：主要用于文本生成、自动文摘、故事创作等任务\n",
      "--------------------------------------------------------------------------------\n",
      "{'type': 'ollama', 'model': 'Qwen/Qwen2-7B-Instruct-GPTQ-Int4', 'global_priority': False}\n",
      "stream=False\n",
      "大型语言模型，通常称为大语言模型（Large Language Models）或超大规模语言模型（Megatron Language Models），是由现代人工智能（AI）研究者构建的一种复杂的深度学习模型，其主要目标是通过处理和生成大量文本数据进行语言理解和生成任务，如回答问题、概括文本、编写代码、生成文本聊天、甚至是撰写短篇小说或论文摘要等。\n",
      "\n",
      "这些模型之所以称为“大型”或“超大规模”，是因为它们拥有数以十亿甚至几百亿参数，以及在训练时使用了海量的训练数据集（比如包含巨量网络文本、书籍、论文等）。这类模型通常基于Transformer架构，在多GPU或多PaddleX集群上训练，能够学习到复杂的语言结构和模式，并展现出令人惊叹的文本生成能力。\n",
      "\n",
      "大语言模型的生成能力通过以下几个关键特征得到体现：\n",
      "\n",
      "1. **文本生成**：能够自然流畅地生成文本，模仿训练集中的各种写作风格和语言特点。\n",
      "2. **多层次上下文理解**：能够考虑文本的上下文信息，写出连贯且符合语法规则的句子。\n",
      "3. **自动纠错与语言风格转换**：在修改错误标点或语法的同时，也可以转换到不同的语言\n",
      "stream=True\n",
      "大型语言模型是一种高级的人工智能系统，其核心是基于大量的文本数据进行训练，能够理解和生成人类语言。这类模型可以用于多种自然语言处理任务，包括但不限于文本生成、文本理解和生成、自然语言问答、情感分析、机器翻译等。它们之所以被称为“大型”，通常是因为它们需要借助大量数据和计算资源进行训练，并且往往会产生非常复杂和丰富的语言输出。\n",
      "\n",
      "大型语言模型的关键特性包括：\n",
      "\n",
      "1. **大规模训练**：这些模型通常通过利用庞大的训练数据集进行多层神经网络的训练，每层网络负责抽取数据中的各种层次特征。\n",
      "\n",
      "2. **上下文理解能力**：由于它们是在复杂文本结构和长时间序列中学习的，大语言模型能够理解丰富的上下文信息，甚至捕捉到长距离的语义关系。\n",
      "\n",
      "3. **生成多样性**：能够根据给定指令生成各种文本，从极短的指令到长篇故事、正式报告、对话等，同时保持语言风格的一致性。\n",
      "\n",
      "4. **自学习能力**：通过不断接受外部反馈和更大量的数据，模型可以持续改进和适应新的语言使用情景。\n",
      "\n",
      "5. **安全和伦理考量**：随着这些技术的普及，人们也越来越关注\n"
     ]
    }
   ],
   "source": [
    "for llm_config in [\n",
    "    {\"type\": \"zerollama\", \"model\": model, \"global_priority\": False},\n",
    "    {\"type\": \"openai\", \"model\": model, \"base_url\": 'http://localhost:8080/v1/', \"global_priority\": False},\n",
    "    {\"type\": \"ollama\", \"model\": model, \"global_priority\": False},\n",
    "]:\n",
    "    print(\"-\" * 80)\n",
    "    print(llm_config)\n",
    "    agent = LLMAgent(\n",
    "        name=\"chatbot\",\n",
    "        llm_config=llm_config,\n",
    "    )\n",
    "\n",
    "    print(\"stream=False\")\n",
    "    reply = agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=False,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    )\n",
    "\n",
    "    print(reply)\n",
    "\n",
    "    print(\"stream=True\")\n",
    "    for part in agent.generate_reply(\n",
    "        messages=[{\"content\": prompt, \"role\": \"user\"}],\n",
    "        stream=True,\n",
    "        options={\"max_tokens\": 1000}\n",
    "    ):\n",
    "        print(part, end=\"\", flush=True)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c423d37-628a-4784-bcb3-64cdf23e356a",
   "metadata": {},
   "source": [
    "运行你会看到stream=False一次性输出，stream=False流式输出。设定输出1000个token，所以会有截断。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a0c819-278c-4545-84e1-657bc9ae36c1",
   "metadata": {},
   "source": [
    "## 总结\n",
    "zerollama.agents 支持 ollama和openai客户端、支持zerollama内部通讯协议。非常灵活。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c3d2a-94c9-4d8d-82b8-a537f463af29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
